{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EfficientNet_sigmoid.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "057922c20da9420c8181992f2841de8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_a281f59d0a794ad68be141e23162afc7",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_4d185d5cb1ec466fbb4e98d2316e7c15",
              "IPY_MODEL_cb52d9b181ec484880b0be61c71f4a18"
            ]
          }
        },
        "a281f59d0a794ad68be141e23162afc7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4d185d5cb1ec466fbb4e98d2316e7c15": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_16f4833823104a82a7a4dba932fa048a",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 266860719,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 266860719,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_52cb731622984229a797aba44799d867"
          }
        },
        "cb52d9b181ec484880b0be61c71f4a18": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_111ad3080385456b9b1776186ed1966f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 254M/254M [00:16&lt;00:00, 16.0MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e42a69507ace4704a0a0997f3e0941d7"
          }
        },
        "16f4833823104a82a7a4dba932fa048a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "52cb731622984229a797aba44799d867": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "111ad3080385456b9b1776186ed1966f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e42a69507ace4704a0a0997f3e0941d7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "12o5QEB9vuV4",
        "colab_type": "text"
      },
      "source": [
        "# Idenidentification Game with EfficientNet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G0ErVwddvx_J",
        "colab_type": "text"
      },
      "source": [
        "### initialization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DvQrN50yAWeM",
        "colab_type": "code",
        "outputId": "40a168e5-e8ca-439c-d166-609745d55b88",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8kNPcLPqAhfA",
        "colab_type": "code",
        "outputId": "b420037e-134e-49d3-97fb-d3eb8b2de0d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cd /content/gdrive/\"My Drive\"/new"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/new\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ntlF6p4Ar9y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip data.zip -d /content && rm *.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WKvr3lk_wFAC",
        "colab_type": "text"
      },
      "source": [
        "#### Prepare for Plotting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uc0Y38SqRcA7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install pycm livelossplot\n",
        "%pylab inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T0iE_gX3WSxf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torchvision.datasets import ImageFolder\n",
        "import torchvision.transforms as transforms\n",
        "from sklearn.metrics import accuracy_score\n",
        "from livelossplot import PlotLosses\n",
        "from pycm import *\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zjMkvOCYwNcU",
        "colab_type": "text"
      },
      "source": [
        "## Initialize dataset\n",
        "We provide two ways of initialize the dataset. The following one is by unzipping the file from beginning. You can choose one you prefer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jX7Aoh7wKHia",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "full_dataset = ImageFolder('/content/train', transforms.Compose([\n",
        "            transforms.Resize(224),\n",
        "            transforms.RandomRotation(10),\n",
        "            transforms.ColorJitter(brightness=0.05, contrast=0.05, saturation=0.05, hue=0.05),\n",
        "            # transforms.RandomResizedCrop(224),\n",
        "            transforms.RandomHorizontalFlip(),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])\n",
        "        ]))\n",
        "train_size = int(0.9 * len(full_dataset))\n",
        "val_size = len(full_dataset) - train_size\n",
        "train_dataset, val_dataset = torch.utils.data.random_split(full_dataset, [train_size, val_size])\n",
        "val_dataset.dataset.transforms = transforms.Compose([transforms.Resize(224), transforms.ToTensor(),transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])])\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "        train_dataset, batch_size=256, shuffle=True,\n",
        "        num_workers=8, pin_memory=True)\n",
        "val_loader = torch.utils.data.DataLoader(\n",
        "        val_dataset, batch_size=256, shuffle=True,\n",
        "        num_workers=8, pin_memory=True)\n",
        "train_all_loader = torch.utils.data.DataLoader(\n",
        "        full_dataset, batch_size=256, shuffle=True,\n",
        "        num_workers=8, pin_memory=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kW7ScJQB1Ad4",
        "colab_type": "text"
      },
      "source": [
        "## Another faster way of initialization\n",
        "These files are prepared in advance since it takes much time to transform imgs to Tensors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iGCg0u_A1Ixf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train_all = torch.load('/content/drive/My Drive/data/X_train_all.py') # all images in train file\n",
        "y_train_all = torch.load('/content/drive/My Drive/data/y_train_all.py') # all labels in train file\n",
        "mean_list = torch.load('/content/drive/My Drive/data/mean_list.py') # mean\n",
        "std_list = torch.load('/content/drive/My Drive/data/std_list.py') # std of 3 channels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DG-7fHq71Yxw",
        "colab_type": "text"
      },
      "source": [
        "#### Sanity check"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NdAThVKW1Iuh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('Check the dataset')\n",
        "print('X_train shape:',X_train_all.shape)\n",
        "print('y_train shape:',y_train_all.shape)\n",
        "print('mean of each channel:', mean_list)\n",
        "print('standard deviation of each channel', std_list)\n",
        "print('normalised data range(not standarized):', X_train_all.min().item(), '~', X_train_all.max().item())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ffFj5Jje1ff4",
        "colab_type": "text"
      },
      "source": [
        "### Stratify the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OIv8VeMx1IqL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "\n",
        "# initialise the stratifiedshufflesplitter\n",
        "# split the whole training dataset into 90% for training and 10% for validation\n",
        "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.1, random_state=42) \n",
        "spt = sss.split(X_train_all, y_train_all)\n",
        "# get the indices of the splited data\n",
        "indices = [(train_idx, validation_idx) for train_idx, validation_idx in spt][0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_aFL_9ku1Ikz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# here the dataset is still in the form of np.array\n",
        "X_train, y_train = X_train_all[indices[0]], y_train_all[indices[0]]\n",
        "X_val, y_val = X_train_all[indices[1]], y_train_all[indices[1]]\n",
        "\n",
        "#Check the size of the data set\n",
        "print('90% training:', X_train.shape, X_val.shape)\n",
        "print('10% validation:', y_train.shape, y_val.shape)\n",
        "print('normalised data range(not standarized):', X_train_all.min().item(), '~', X_train_all.max().item())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "piO48k5K1nZo",
        "colab_type": "text"
      },
      "source": [
        "### Create custom dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o6B_vxRP1lKE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import Dataset\n",
        "from PIL import Image\n",
        "\n",
        "# Custom Dataset for performing Stratified Shuffle Split on ImageFolder datasets\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, data, targets, transform=None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            dataset: an ImageFolder containing the full set of data to be subsampled\n",
        "            indices: array-like containing the stratified shuffle indices\n",
        "            transform (callable, optional): Optional transform to be applied\n",
        "                on a sample.\n",
        "        \"\"\"\n",
        "        # Note that samples are just paths to image files\n",
        "        self.data = data\n",
        "        self.targets = targets\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        sample, label = self.data[idx], self.targets[idx]\n",
        "        if self.transform:\n",
        "            sample = self.transform(sample)\n",
        "        return sample, label"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F2cpNKcZ1s8Y",
        "colab_type": "text"
      },
      "source": [
        "### Data-Arguementation\n",
        "We resize the original pritures to 224*224 to fit the EfficientNet structure."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PzA8oi5N1lIA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torchvision.transforms import *\n",
        "\n",
        "# Transformations\n",
        "# As for this model, we have used pretrained model which has a fixed input\n",
        "# pixel size of 224*224. We have resized the 64*64 pixels picture to 224*224\n",
        "\n",
        "# Two types of data augmentation applied here:\n",
        "# 1.randomly rotate by 10 degrees\n",
        "# 2.flip horizontally with a probability of 0.5\n",
        "train_transform = Compose([ToPILImage(),\n",
        "              transforms.Resize(224),\n",
        "              RandomRotation(10),\n",
        "              RandomHorizontalFlip(p=0.5),\n",
        "              ToTensor(),\n",
        "              Normalize(mean_list, std_list)])\n",
        "\n",
        "#In Validation and Test Mode we only want to normalize our images\n",
        "validation_test_transform = Compose([ToPILImage(),\n",
        "                    transforms.Resize(224),\n",
        "                    ToTensor(),\n",
        "                    Normalize(mean_list, std_list)])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M2QKU-Te1yGo",
        "colab_type": "text"
      },
      "source": [
        "### Create Dataloader for training and validation "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qvN65f7t1lFI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data = CustomDataset(X_train, y_train.long(), transform=train_transform)\n",
        "val_data = CustomDataset(X_val, y_val.long(), transform=validation_test_transform)\n",
        "train_all_data = CustomDataset(X_train_all, y_train_all.long(), transform=train_transform)\n",
        "\n",
        "batch_size = 256\n",
        "test_batch_size = 256\n",
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True)\n",
        "val_loader = torch.utils.data.DataLoader(val_data, batch_size=test_batch_size, shuffle=False, num_workers=2, pin_memory=True)\n",
        "train_all_loader = torch.utils.data.DataLoader(train_all_data, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VD6tn67ixnT5",
        "colab_type": "text"
      },
      "source": [
        "## Initialize EfficientNet\n",
        "We choose the most advanced CNN at the present day, the EfficientNet which was trained and tested on ImageNet.[1] https://arxiv.org/pdf/1905.11946.pdf By fixing the all the parameters in the exiting pretrained layers, we are keeping all the features that the network has learnt from the ImageNet. Then we added one new linear forward layer at the bottom of the network with a dropout layer to overcome the overfitting problem. Then we traines the parameters which would extract the feature from the 1000 output neurons to 200 classes. In this way, our new model's computational cost is acceptable, and the accuracy is expected to be good."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dUeAvjo1RAla",
        "colab_type": "code",
        "outputId": "3710e731-b22b-43aa-e916-7693cfd1ec11",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304,
          "referenced_widgets": [
            "057922c20da9420c8181992f2841de8f",
            "a281f59d0a794ad68be141e23162afc7",
            "4d185d5cb1ec466fbb4e98d2316e7c15",
            "cb52d9b181ec484880b0be61c71f4a18",
            "16f4833823104a82a7a4dba932fa048a",
            "52cb731622984229a797aba44799d867",
            "111ad3080385456b9b1776186ed1966f",
            "e42a69507ace4704a0a0997f3e0941d7"
          ]
        }
      },
      "source": [
        "!pip install efficientnet_pytorch\n",
        "from efficientnet_pytorch import EfficientNet\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "\n",
        "model = EfficientNet.from_pretrained('efficientnet-b7')\n",
        "for name, param in model.named_parameters():\n",
        "  param.requires_grad = False\n",
        "model = nn.Sequential(model, nn.Dropout(p=0.4, inplace=False), nn.Linear(1000,200))\n",
        "mdoel = model.cuda()\n",
        "optimizer = torch.optim.Adam(model.parameters(),lr=2e-3, weight_decay=0.12)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting efficientnet_pytorch\n",
            "  Downloading https://files.pythonhosted.org/packages/b8/cb/0309a6e3d404862ae4bc017f89645cf150ac94c14c88ef81d215c8e52925/efficientnet_pytorch-0.6.3.tar.gz\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from efficientnet_pytorch) (1.5.0+cu101)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch->efficientnet_pytorch) (0.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch->efficientnet_pytorch) (1.18.4)\n",
            "Building wheels for collected packages: efficientnet-pytorch\n",
            "  Building wheel for efficientnet-pytorch (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for efficientnet-pytorch: filename=efficientnet_pytorch-0.6.3-cp36-none-any.whl size=12422 sha256=14a0e4c915643f0cd678f333b9664b2cf84d3d906ca013547063d97b1e12e8b6\n",
            "  Stored in directory: /root/.cache/pip/wheels/42/1e/a9/2a578ba9ad04e776e80bf0f70d8a7f4c29ec0718b92d8f6ccd\n",
            "Successfully built efficientnet-pytorch\n",
            "Installing collected packages: efficientnet-pytorch\n",
            "Successfully installed efficientnet-pytorch-0.6.3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://github.com/lukemelas/EfficientNet-PyTorch/releases/download/1.0/efficientnet-b7-dcc49843.pth\" to /root/.cache/torch/checkpoints/efficientnet-b7-dcc49843.pth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "057922c20da9420c8181992f2841de8f",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=266860719.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Loaded pretrained weights for efficientnet-b7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oTWCENYpRUmA",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZD-2tOFLxr9_",
        "colab_type": "text"
      },
      "source": [
        "### Preparing for training session"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2spDuOXvSiPj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This part are computing the accuracy. It is able to compute top-1 and top-5 accuracy if needed \n",
        "class AverageMeter(object):\n",
        "  \"\"\"Computes and stores the average and current value\"\"\"\n",
        "  def __init__(self, name, fmt=':f'):\n",
        "    self.name = name\n",
        "    self.fmt = fmt\n",
        "    self.reset()\n",
        "\n",
        "  def reset(self):\n",
        "    self.val = 0\n",
        "    self.avg = 0\n",
        "    self.sum = 0\n",
        "    self.count = 0\n",
        "\n",
        "  def update(self, val, n=1):\n",
        "    self.val = val\n",
        "    self.sum += val * n\n",
        "    self.count += n\n",
        "    self.avg = self.sum / self.count\n",
        "\n",
        "  def __str__(self):\n",
        "    fmtstr = '{name} {val' + self.fmt + '} ({avg' + self.fmt + '})'\n",
        "    return fmtstr.format(**self.__dict__)\n",
        "\n",
        "def accuracy(output, target, topk=(1,)):\n",
        "  \"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"\n",
        "  maxk = max(topk)\n",
        "  batch_size = target.size(0)\n",
        "\n",
        "  _, pred = output.topk(maxk, 1, True, True)\n",
        "  pred = pred.t()\n",
        "  correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
        "\n",
        "  res = []\n",
        "  for k in topk:\n",
        "    correct_k = correct[:k].view(-1).float().sum(0, keepdim=True)\n",
        "    res.append(correct_k.mul_(100.0 / batch_size))\n",
        "  return res\n",
        "\n",
        "        \n",
        "def train(train_loader, model, criterion, optimizer, liveloss):\n",
        "  batch_time = AverageMeter('Time', ':6.3f')\n",
        "  data_time = AverageMeter('Data', ':6.3f')\n",
        "  losses = AverageMeter('Loss', ':.4e')\n",
        "  top1 = AverageMeter('Acc@1', ':6.2f')\n",
        "  top5 = AverageMeter('Acc@5', ':6.2f')\n",
        "\n",
        "  # switch to train mode\n",
        "  model.eval()\n",
        "\n",
        "  end = time.time()\n",
        "  for i, (images, target) in enumerate(train_loader):\n",
        "    # measure data loading time\n",
        "    data_time.update(time.time() - end)\n",
        "    images = images.cuda(non_blocking=True)\n",
        "    target = target.cuda(non_blocking=True)\n",
        "\n",
        "    # compute output\n",
        "    output = model(images)\n",
        "    loss = criterion(output, target)\n",
        "\n",
        "    # measure accuracy and record loss\n",
        "    acc1, acc5 = accuracy(output, target, topk=(1, 5))\n",
        "    losses.update(loss.item(), images.size(0))\n",
        "    top1.update(acc1[0], images.size(0))\n",
        "    top5.update(acc5[0], images.size(0))\n",
        "\n",
        "    # compute gradient and do SGD step\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # measure elapsed time\n",
        "    batch_time.update(time.time() - end)\n",
        "    end = time.time()\n",
        "    if i%10 == 0:\n",
        "      liveloss.update({'loss':losses.avg, 'acc':top1.avg})\n",
        "      liveloss.draw()\n",
        "  return losses.avg, top1.avg\n",
        "\n",
        "\n",
        "\n",
        "def validate(val_loader, model, criterion, liveloss):\n",
        "  batch_time = AverageMeter('Time', ':6.3f')\n",
        "  losses = AverageMeter('Loss', ':.4e')\n",
        "  top1 = AverageMeter('Acc@1', ':6.2f')\n",
        "  top5 = AverageMeter('Acc@5', ':6.2f')\n",
        "  # switch to evaluate mode\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    end = time.time()\n",
        "    for i, (images, target) in enumerate(val_loader):\n",
        "      images = images.cuda(non_blocking=True)\n",
        "      target = target.cuda(non_blocking=True)\n",
        "      # compute output\n",
        "      output = model(images)\n",
        "      loss = criterion(output, target)\n",
        "      # measure accuracy and record loss\n",
        "      acc1, acc5 = accuracy(output, target, topk=(1, 5))\n",
        "      losses.update(loss.item(), images.size(0))\n",
        "      top1.update(acc1[0], images.size(0))\n",
        "      top5.update(acc5[0], images.size(0))\n",
        "      # measure elapsed time\n",
        "      batch_time.update(time.time() - end)\n",
        "      end = time.time()\n",
        "      if i%10 == 0:\n",
        "        liveloss.update({'val_loss':losses.avg, 'val_acc':top1.avg})\n",
        "        liveloss.draw()\n",
        "  return losses.avg, top1.avg\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fUkMFlQvRWvr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "liveloss = PlotLosses()\n",
        "for epoch in range(100): # The x-label here is not epochs but number of minibatches, so that we can check its speed easier.\n",
        "    train_loss, train_accuracy = train(train_loader, model, criterion, optimizer, liveloss\n",
        "\n",
        "    validation_loss, validation_accuracy = validate(val_loader, model, criterion, liveloss)\n",
        "\n",
        "    scheduler.step()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F45O2kjI56BT",
        "colab_type": "text"
      },
      "source": [
        "![title](./train_val.jpg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QbuDfojeyIM5",
        "colab_type": "text"
      },
      "source": [
        "### Train on the whole train dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tUcHuE0Pc7Rw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# remember to reset the model using the initializarion part above\n",
        "\n",
        "liveloss = PlotLosses()\n",
        "for epoch in range(50):\n",
        "    train_loss, train_accuracy = train(train_all_loader, model, criterion, optimizer, liveloss)\n",
        "    scheduler.step()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zn-jFHq158lp",
        "colab_type": "text"
      },
      "source": [
        "![title](./train1.jpg)\n",
        "![title](./train2.jpg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZZtMrywhym5T",
        "colab_type": "text"
      },
      "source": [
        "### Save the trained model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LVQYia2WMQzx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.save({\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'loss': train_loss\n",
        "            }, '/content/gdrive/My Drive/id/eff_model.pth')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nj7-4Z3qu3fa",
        "colab_type": "text"
      },
      "source": [
        "### Load the model if needed"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XHdkZCtqMQo4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "checkpoint = torch.load('/content/gdrive/My Drive/id/eff_model.pt')\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "epoch = checkpoint['epoch']\n",
        "loss = checkpoint['loss']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0MhLjwRTzF72",
        "colab_type": "text"
      },
      "source": [
        "### Preparing the test dataset\n",
        "We use the five corp operation here to calculate a mean of the images, which could improve the accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ibhzF3b0sQSq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])\n",
        "test_dataset = ImageFolder('/content/test', transforms.Compose([\n",
        "            transforms.Resize(256),\n",
        "            transforms.FiveCrop(224),\n",
        "            transforms.Lambda(lambda crops: torch.stack([transforms.ToTensor()(crop) for crop in crops])),\n",
        "            transforms.Lambda(lambda crops: torch.stack([normalize(crop) for crop in crops]))\n",
        "        ]))\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "        test_dataset, batch_size=64, shuffle=False, drop_last=False,\n",
        "        num_workers=8)\n",
        "def test(test_loader, model):\n",
        "  pred = None\n",
        "  # switch to evaluate mode\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    end = time.time()\n",
        "    for i, (images, target) in enumerate(test_loader):\n",
        "      images = images.cuda()\n",
        "      bs, ncrops, c, h, w = images.size()\n",
        "      temp_output = model(images.view(-1, c, h, w))\n",
        "      outputs = temp_output.view(bs, ncrops, -1).mean(1)\n",
        "      _, prediction = torch.max(outputs, 1)\n",
        "      # measure accuracy and record loss\n",
        "      pred = prediction if pred is None else torch.cat([pred, prediction])\n",
        "  return pred"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rJsD_rCqvLDe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_y = test(test_loader, model)\n",
        "\n",
        "# Create and write submission csv file\n",
        "import csv\n",
        "with open('./eff_result.csv', 'w', newline='') as file:\n",
        "  writer = csv.writer(file)\n",
        "  writer.writerow([\"Filename\", \"Label\"])\n",
        "  for i in range(10000):\n",
        "      writer.writerow([test_dataset.samples[i][0].split('/')[-1].replace('JPEG','jpeg'), str(int(test_y[i]))])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vwmj8fgI9jt2",
        "colab_type": "text"
      },
      "source": [
        "# Going deeper into accuracy improvement\n",
        "Now that we have got a trained model with about 77% accuracy, it is reasonable to cinsider that whether combining different trained models together improves the accuracy further.\n",
        "Then we choose 6 trained model, apply them on the dataset and get the output [10000, 1] tensors. Then we design a simple NN, and use the prepared tensors to train it. Finally we can get a improved result and the computational cost of the simple NN is negligible."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w2n1H7_z_ZKN",
        "colab_type": "text"
      },
      "source": [
        "### Combination of 6 pre-trained models\n",
        "As we can see that by using models pre-trained on ImageNet. We can achieve a reasonably high accuracy in the first epochs. There is a simple idea we to just combine all the pre-trained models and train on the ouput given by these pre-trained models. Each pre-trained models has 1000 outputs. We can see these outputs as 1000 features of the input image. We have appended corresponding features from each model and flattend out the tensor. So the same feature from each model will cluster together. The advantage of this is once the data was prepared, the training time is less than 5 mins to get 30 epochs with an 74% accuracy achived on the validation set. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_1c6O_Ko_hOF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = 'cpu'\n",
        "if torch.cuda.device_count() > 0 and torch.cuda.is_available():\n",
        "    print(\"Cuda installed! Running on GPU!\")\n",
        "    device = 'cuda'\n",
        "else:\n",
        "    print(\"No GPU available!\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gwy1MJ4DBmW7",
        "colab_type": "text"
      },
      "source": [
        "#### Load the tensors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2uRmAafX_a4P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We have prepared the data with 6 pre-trained models including \n",
        "# vgg16_bn, vgg_19_bn, resnent50, DenseNet161, EfficientNet, WideRes\n",
        "# This data preparation can be find in the data preparation notebook\n",
        "X_full_dataset = torch.load('X_all_prob.pt') \n",
        "y_full_dataset = torch.load('y_all_pre.pt') "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1dMhrWOv_axs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "\n",
        "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.1, random_state=42) \n",
        "spt = sss.split(X_full_dataset, y_full_dataset)\n",
        "# get the indices of the splited data\n",
        "indices = [(train_idx, validation_idx) for train_idx, validation_idx in spt][0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RwFtgNzd_lwy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# here the dataset is still in the form of np.array\n",
        "X_train, y_train = X_full_dataset[indices[0]], y_full_dataset[indices[0]]\n",
        "X_val, y_val = X_full_dataset[indices[1]], y_full_dataset[indices[1]]\n",
        "\n",
        "#Check the size of the data set\n",
        "print(X_train.shape, X_val.shape)\n",
        "print(y_train.shape, y_val.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4NjmpjiPBqu7",
        "colab_type": "text"
      },
      "source": [
        "#### prepareing for training part"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JG-W4gEx_pXV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model, optimizer, criterion, data_loader):\n",
        "    model.train()\n",
        "    train_loss, train_accuracy = 0, 0\n",
        "    for X, y in data_loader: \n",
        "        X, y = X.to(device), y.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        a2 = model(X.view(-1, 6000).float()) \n",
        "        loss = criterion(a2, y) \n",
        "        loss.backward()\n",
        "        train_loss += loss*X.size(0)\n",
        "        y_pred = F.log_softmax(a2, dim=1).max(1)[1]\n",
        "        train_accuracy += accuracy_score(y.cpu().numpy(), y_pred.detach().cpu().numpy())*X.size(0)\n",
        "        optimizer.step()  \n",
        "        \n",
        "    return train_loss/len(data_loader.dataset), train_accuracy/len(data_loader.dataset)\n",
        "\n",
        "def validate(model, criterion, data_loader):\n",
        "    model.eval()\n",
        "    validation_loss, validation_accuracy = 0., 0.\n",
        "    for X, y in data_loader:\n",
        "        with torch.no_grad():\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            a2 = model(X.view(-1, 6000).float())\n",
        "            loss = criterion(a2, y)\n",
        "            validation_loss += loss*X.size(0)\n",
        "            y_pred = F.log_softmax(a2, dim=1).max(1)[1]\n",
        "            validation_accuracy += accuracy_score(y.cpu().numpy(), y_pred.cpu().numpy())*X.size(0)\n",
        "            \n",
        "    return validation_loss/len(data_loader.dataset), validation_accuracy/len(data_loader.dataset)\n",
        "\n",
        "def evaluate(model, data_loader):\n",
        "    model.eval()\n",
        "    ys, y_preds = [], []\n",
        "    for X, y in data_loader:\n",
        "        with torch.no_grad():\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            a2 = model(X.view(-1, 6000).float())\n",
        "            y_pred = F.log_softmax(a2, dim=1).max(1)[1]\n",
        "            ys.append(y.cpu().numpy())\n",
        "            y_preds.append(y_pred.cpu().numpy())\n",
        "            \n",
        "    return np.concatenate(y_preds, 0),  np.concatenate(ys, 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wJ3A0Vdx_pUP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "seed = 42\n",
        "lr = 1e-2\n",
        "momentum = 0.9\n",
        "batch_size = 64\n",
        "test_batch_size = 100\n",
        "n_epochs = 30"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W2xlYeQh_yBH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train_dataset = TensorDataset(X_train, y_train)\n",
        "X_val_dataset = TensorDataset(X_val, y_val)\n",
        "X_full = TensorDataset(X_full_dataset, y_full_dataset)\n",
        "train_loader = DataLoader(X_train_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
        "validation_loader = DataLoader(X_val_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
        "train_all_loader = DataLoader(X_full, batch_size=batch_size, shuffle=True, num_workers=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ElefEstY_ZHC",
        "colab_type": "text"
      },
      "source": [
        "#### Design a simple NN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DHCpq3M-_1Jy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SimpleNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleNet, self).__init__()\n",
        "        self.linear_1 = nn.Linear(6000, 1000)\n",
        "        self.d2 = nn.Dropout(0.2)\n",
        "        self.linear_2 = nn.Linear(1000, 200)\n",
        "        self.act = nn.ReLU()\n",
        "        \n",
        "    def forward(self, x):\n",
        "        z1 = self.linear_1(x)\n",
        "        a1 = self.act(z1)\n",
        "        a1 = self.act(self.d2(a1))\n",
        "        z2 = self.linear_2(a1)\n",
        "        return z2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L0KqjRsE_ZD6",
        "colab_type": "text"
      },
      "source": [
        "#### Plot the training progeass"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-U4G1uR3_T55",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "liveloss = PlotLosses()\n",
        "model = SimpleNet().to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FMD-fJ_h_5UB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# for each 30 epoch. Reducing the lr by 1/2\n",
        "# starting from 0.001\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', \n",
        "                                                       factor=0.5, patience=0, verbose=True, \n",
        "                                                       threshold=0.001, threshold_mode='rel', \n",
        "                                                       cooldown=0, min_lr=0, eps=1e-08)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "for epoch in range(30):\n",
        "    logs = {}\n",
        "    train_loss, train_accuracy = train(model, optimizer, criterion, train_loader)\n",
        "\n",
        "    logs['' + 'log loss'] = train_loss.item()\n",
        "    logs['' + 'accuracy'] = train_accuracy.item()\n",
        "\n",
        "    validation_loss, validation_accuracy = validate(model, criterion, validation_loader)\n",
        "    logs['val_' + 'log loss'] = validation_loss.item()\n",
        "    logs['val_' + 'accuracy'] = validation_accuracy.item()\n",
        "\n",
        "\n",
        "    scheduler.step(validation_loss)\n",
        "    liveloss.update(logs)\n",
        "    liveloss.draw()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Jaw7PdsAAkp",
        "colab_type": "text"
      },
      "source": [
        "![title](./com1.jpg)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oeYDKOzdAA09",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.save(model.state_dict(), 'val_train_combined.pt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pO9rJqgAAIv5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Check macro F1-score for the validation set\n",
        "from sklearn.metrics import f1_score\n",
        "model.load_state_dict(torch.load('val_train_combined.pt'))\n",
        "val_ypred, y_val = evaluate(model, validation_loader)\n",
        "val_f1 = f1_score(y_val, val_ypred, average='macro')\n",
        "print(val_f1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PEwPVh9yALC6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "liveloss = PlotLosses()\n",
        "model = SimpleNet().to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bOUaDm7mAMqm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# for each 30 epoch. Reducing the lr by 1/2\n",
        "# starting from 0.005\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', \n",
        "                                                       factor=0.5, patience=3, verbose=True, \n",
        "                                                       threshold=0.001, threshold_mode='rel', \n",
        "                                                       cooldown=0, min_lr=0, eps=1e-08)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "for epoch in range(50):\n",
        "    logs = {}\n",
        "    train_loss, train_accuracy = train(model, optimizer, criterion, train_all_loader)\n",
        "\n",
        "    logs['' + 'log loss'] = train_loss.item()\n",
        "    logs['' + 'accuracy'] = train_accuracy.item()\n",
        "\n",
        "    scheduler.step(train_accuracy)\n",
        "    liveloss.update(logs)\n",
        "    liveloss.draw()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ity4LbenAP74",
        "colab_type": "text"
      },
      "source": [
        "![title](./com2.jpg)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rJFJkp95AREo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.save(model.state_dict(), 'all_train_combined.pt')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}